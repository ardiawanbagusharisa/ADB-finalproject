# Copilot Instructions for Sumobot Natural Query Project

This project aims to build a **Natural Language Query Interface** for Sumobot game data as part of an Advanced Database class. The goal is to allow users to ask questions in plain English (e.g., "Who won the most games?") and retrieve answers from the game data without writing SQL.

## 1. Project Scope & Architecture

The system should implement a **Text-to-SQL** (or Text-to-Dataframe) pipeline:
1.  **User Input**: Natural language questions (see `NaturalQueryExamples.csv`).
2.  **Translation Layer**: An LLM (Local or API) converts the question into a structured query (SQL).
3.  **Execution Layer**: The query runs against a structured database (SQLite/DuckDB) created from the CSV logs.
4.  **Response**: The system returns the answer to the user.

**Hardware Constraint**: The user is running on a laptop with an NVIDIA GPU (RTX series). Prefer solutions that can run locally (e.g., using Ollama, Llama.cpp, or HuggingFace transformers with 4-bit quantization) or lightweight API calls.

## 2. Data Sources & Schema

### Primary Data
-   **`GameRecord_Short.csv`**: The main flattened dataset containing game events, positions, and outcomes.
    -   *Key Columns*: `GameIndex`, `GameWinner`, `Timestamp`, `Actor`, `Action`, `BotPosX`, `BotPosY`.
    -   *Usage*: This should be loaded into a relational database table (e.g., `game_events` or normalized into `games` and `events`).

### Secondary Data
-   **`Sumobot_GameSummary.csv`**: High-level game stats. Useful for quick aggregation queries.
-   **`Timer_.../`**: Raw JSON logs. Use these only if the CSVs are missing critical details.

### Query Examples
-   **`NaturalQueryExamples.csv`**: Use these to test and validate the system.
    -   *Examples*: "Show me the average game duration", "Compare win-rate of Bot 0 and Bot 1".

## 3. Task Roadmap for AI Agents

When assisting with this project, prioritize these steps:

1.  **Schema Generation**:
    -   Analyze `GameRecord_Short.csv`.
    -   Propose a SQL schema (CREATE TABLE statements).
    -   Write a script to load CSV data into a SQLite database (`sumobot.db`).

2.  **Natural Query System Implementation**:
    -   Create a Python script/notebook.
    -   Implement a function `ask_database(question: str) -> result`.
    -   Use prompt engineering to provide the LLM with the database schema and ask for SQL.
    -   *Note*: Handle "hallucinations" by validating SQL before execution if possible.

3.  **Documentation (README.md)**:
    -   Generate a comprehensive `README.md`.
    -   Include **exact** installation steps (`pip install ...`).
    -   Explain how to set up the local LLM (if applicable) or API keys.
    -   Provide a "Quick Start" command to run the query interface.

## 4. Coding Conventions

-   **Language**: Python 3.10+.
-   **Libraries**: `pandas`, `sqlite3`, `sqlalchemy`. For LLM: `langchain` or direct `openai`/`transformers` usage.
-   **Style**: Modular code. Separate database loading logic from query logic.
-   **Error Handling**: Gracefully handle invalid SQL generated by the LLM.

## 5. Specific "Gotchas"
-   The CSV contains per-frame/per-action data. Aggregations (AVG, SUM) need to be careful about counting rows vs. counting games.
-   `GameIndex` resets or is unique? Check if `GameTimestamp` + `GameIndex` is the true unique key.
